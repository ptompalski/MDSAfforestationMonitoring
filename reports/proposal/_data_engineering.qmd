### Train-Test Splitting

Splitting the dataset into training and testing subsets is necessary to prevent data leakage during model training,
but doing so requires some nuance due to it's heirarchical structure. 
We perform the train-test split using proportions of **unique sites** rather than rows, 
to ensure pixels and/or time step records for a particular site appear in only one of the two subsets. 
This will allow for analysis of time changes in the vegetation indices for a given site using more complex deep learning models in the future.

### Missing Data

As can be observed in @fig-missing_rows, there are many missing records across the dataset that must be handled prior to modelling.

![A plot visualizing missing record patterns across the training dataset. 
Grey-coloured records indicate rows that have recorded values.](../../img/missing_rows.png){#fig-missing_rows width=70%}

We find excessive missingness in the columns `PlantDt`, `Type`, `NmbrPIO`, `NmbrPIR`, and `NmbrPIT`. 
The columns `PlantDt`, `NmbrPIO`, `NmbrPIR`, and `NmbrPIT` relate to sites where replanting has occured, 
and can be removed as they are outside of the project scope 
Additionally, `Type` can be fully imputed via string processing on the `SpcsCmp` column. 
There is a direct correlation between missingness in survivial rate and time of assesment:
if the survival rate is recorded, the time at which it was recorded is also present.
This will allow for tracking of temporal dependence without the need for imputation, which will be elaborated further upon in the following sections.
Additionally, a similar pattern appears between the ten vegetation indices, meaning the few missing values can be dropped without significant loss of data.

### Feature Selection and Engineering

As mentioned in @sec-data_description, strong collinearity between the vegetation indices indicates a need for feature selection. 
As a baseline method, we will use **Recursive Feature Elimination**, due to its compatbility with many nonlinear ML models [@scikit-learn]. 
We also propose the use of **Bayesian Model Averaging**,
as such a method is suitable for an analysis of multiple competing models, varying in features and architecture [@hoeting1998bayesian].
It may also be necessary to leverage these results with domain knowlege of the characteristics and relationships of each index as outlined by @zeng2022optical.

Very little feature engineering will be performed during this analysis. 
However, we aim to experiment with tree density (number of trees per unit area) -derived from `Planted` and `Area_ha`- as a predictor.

### Data Pivoting

Most machine learning models require the input data to contain just one target column. Therefore,
we will pivot the seven target columns into just one, 
while keeping track of temporality using the trailing digit of the column names and the assesment dates.
We will then remove rows with missing survival rate records, and rows with mismatching assesment and imaging dates.

### Conversion to Classifier Problem

Since the survival rates are given as real-valued proportions between 0% and 100%,
they must be converted to binary classes at the very least, to simplify and align the analysis with the project goals. 
Special care an experimentation will be required in deciding a threshold between classes,
as most survival rates are skewed towards 100%. There is a trade-off that must be considered:
A low threshold may be more appropriate for the analysis but may lead to heavy class imbalance.